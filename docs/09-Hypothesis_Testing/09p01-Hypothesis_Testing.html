<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>CEMA 0928: Statistics in the Real World</title>
    <meta charset="utf-8" />
    <meta name="author" content="Anthony Scotina" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# CEMA 0928: Statistics in the Real World
## Understanding Hypothesis Tests
### Anthony Scotina

---






# Needed Packages 


```r
library(tidyverse)
library(infer)
library(nycflights13)
```

---

class: center, middle

# When inference is not needed

---

# Back to the `flights` data frame

Sometimes, it isn't necessary to perform a statistical hypothesis test. 
- *Always* do **exploratory data analysis**!

--


```r
View(flights)
```

---

# Average Flight Times 

Assuming two flights leave from New York, which do you think is longer?
- The flight to **Boston**?
- The flight to **San Francisco**?

--


```r
bos_sfo = flights %&gt;%
  na.omit() %&gt;% # removes flights with missing info
  filter(dest %in% c("BOS", "SFO")) 
```

---

# Exploratory Data Analysis: Summary Statistics


```r
bos_sfo %&gt;%
  group_by(dest) %&gt;%
  summarize(mean = mean(air_time), sd = sd(air_time))
```

```
`summarise()` ungrouping output (override with `.groups` argument)
```

```
# A tibble: 2 x 3
  dest   mean    sd
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
1 BOS    39.0  4.95
2 SFO   346.  17.2 
```

---

# Exploratory Data Analysis: Data Visualization


```r
ggplot(data = bos_sfo, mapping = aes(x = dest, y = air_time)) + 
  geom_boxplot()
```

&lt;img src="09p01-Hypothesis_Testing_files/figure-html/unnamed-chunk-6-1.png" width="45%" /&gt;

---

# Summary

There is *no overlap at all* in the boxplots!
- This means that the air time for San Francisco flights is **statistically greater** than the air time for Boston flights (which isn't surprising). 

The procedures that follow *would not be necessary* for data such as these. 
- Always do **exploratory data analysis**!!!

---

class: center, middle

# Basics of Hypothesis Testing

---

# Hypothesis Tests

In a statistical **hypothesis test**, we use *sample data* to help us decide between two competing hypotheses about a *population parameter*. 
- The **null hypothesis** 
    - `\(H_{0}\)`
- The **alternative hypothesis**
    - `\(H_{a}\)`

--

The **alternative hypothesis** is the claim for which we seek significant evidence. 
- **Example**: Are the flight times for flights from NY to BOS or SFO *significantly different*?

--

The **null hypothesis** is usually a claim of *no effect* or *no difference*. 
- **Example**: There is *no difference* in the flight times from NY to BOS or SFO. 

---

# Assessing Strength of Evidence

First, we *assume that the null hypothesis is true*. 
- Then, we determine *how unlikely* it would be to observe **sample statistics** as extreme (or more extreme) than the ones in the original sample. 

--

**Don't worry!** This might not sound immediately straightforward. 
- Seasoned scientists often misunderstand statistical hypothesis tests. 

--

**Criminal trial analogy**: *Innocent until proven guilty*

---

# Two Possible Conclusions

These are the *only two* possible conclusions to a statistical hypothesis test:

- **Reject** the null hypothesis `\(H_{0}\)` `\(\rightarrow\)` **Accept** the alternative hypothesis `\(H_{a}\)` 
- **Fail to reject** the null hypothesis `\(H_{0}\)`

Therefore, *never* write "Accept `\(H_{0}\)`" when you mean "Fail to reject `\(H_{0}\)`!"

---

# Types of Errors

Hypothesis tests *are not perfect*. Unfortunately, there exists the possibility of your conclusion being *incorrect*. 

--

Similar to a criminal trial:
- an *innocent* person is wrongly convicted (found guilty), or
- a *guilty* person is wrongly set free (found not guilty)

---

# Types of Errors

Let's assume the following: 
`$$H_{0}: \text{person is innocent},\ H_{a}: \text{person is guilty}$$`

The two **errors** are:
- Reject `\(H_{0}\)` when `\(H_{0}\)` is true (**Type I Error**)
- Fail to reject `\(H_{0}\)` when `\(H_{0}\)` is false (**Type II Error**)

--

When you use a *sample* to make inferences about a *population*, there is a chance that your inferences are incorrect!
- With any procedure, there is a chance of Type I Error and a chance of Type II Error. 

---

# Type I and Type II Errors

.center[
&lt;img src="decision_table.png" width="80%" /&gt;
]

Of course, we want a *small probability* of making an error!

--

- The probability of Type I Error is denoted by `\(\alpha\)` ("alpha") and is called the **significance level** of the hypothesis test. 
- The probability of Type II Error is denoted by `\(\beta\)` ("beta").

---

# Significance Level

We want `\(\alpha\)` and `\(\beta\)` as close to 0 as possible, because this would minimize our chance of making an error in our hypothesis test conclusions. 

Usually, we set `\(\alpha\)` (the **significance level**) before the hypothesis test is conducted. 
- We then judge the "evidence" against `\(\alpha\)`. 

--

Common values of `\(\alpha\)` are `\(0.05\)`, `\(0.01\)`, and `\(0.10\)`. 
- If we set `\(\alpha=0.05\)`, this means that we are using a procedure that, when used *over and over with different samples*, rejects a TRUE `\(H_{0}\)` 5% of the time. 

---

# Statistical Significance

The results from a hypothesis test are **statistically significant** if they are *more extreme* than what we would expect to see by random chance, **if the null hypothesis were true**. 
- In other words, we have *convincing evidence* in favor of the alternative hypothesis, allowing us to generalize our *sample* results to the claim about the *population*. 

--

**Example**: Back to Sarah the chimp...

---

# Sarah the chimp

.pull-left[
- In 1978, researchers Premack and Woodruff published a study in *Science* magazine, reporting an experiment where an adult chimpanzee named Sarah was shown videotapes of eight different scenarios of a human being faced with a problem.

- After each videotape showing, she was presented with two photographs, one of which depicted a possible solution to the problem.

- Sarah could pick the photograph with the correct solution for seven of the eight problems!
]

.pull-right[
![](chimp.jpeg)
]

---

# How?!

What are **two possible explanations** for Sarah getting 7 correct answers out of 8?

--

1. Sarah was just guessing and got lucky. 

2. Sarah can do better than just guessing. 

--

Explanation 1 is the **null hypothesis**. Is there enough evidence to reject the explanation that Sarah was *guessing*?

---

# Simulating Guessing

If Sarah were just guessing, we would *expect* the number of correct guesses to be 4. 

- However, not every set of 8 coin tosses will result in 4 heads. 

- Let's repeat the set of 8 coin tosses many times, to generate the pattern for correct answers that could happen in the long run, **under the assumption that Sarah is just guessing**. 

--
.center[
&lt;img src="09p01-Hypothesis_Testing_files/figure-html/unnamed-chunk-8-1.png" width="45%" /&gt;
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
